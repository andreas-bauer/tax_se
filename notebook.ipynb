{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import hashlib\n",
    "import bz2\n",
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    import orjson as json\n",
    "except ImportError:\n",
    "    import json\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_location = pd.DataFrame([], columns=['user_id', 'month', 'country']) # load here your users' location for each month (captures user locations over time )\n",
    "\n",
    "# if time information are not available, user_location can be a dict mapping persons to a country (static; does not capture user locations over time)\n",
    "user_location = {\n",
    "    'c8b39e436e0d96f0c8f7c66908a02d15': 'Germany',\n",
    "    '3425a6f8362416088ea186018a0f5d71': 'Sweden'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(user_location) == dict:\n",
    "    humans = set(user_location)\n",
    "else:\n",
    "    humans = set(user_location.user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hide(a_string: str):\n",
    "    if a_string:\n",
    "        return hashlib.md5(a_string.encode('utf-8')).hexdigest()\n",
    "    return None\n",
    "\n",
    "def load_data(file_path: Path):\n",
    "    with open(file_path, 'rb') as file_handle:\n",
    "        byte_data = bz2.decompress(file_handle.read())\n",
    "        return json.loads(byte_data)\n",
    "\n",
    "def remove_fields(data, fields_to_remove):\n",
    "    if isinstance(data, dict):\n",
    "        return {k: remove_fields(v, fields_to_remove) for k, v in data.items() if k not in fields_to_remove}\n",
    "    if isinstance(data, list):\n",
    "        return [remove_fields(i, fields_to_remove) for i in data]\n",
    "    return data\n",
    "\n",
    "def anonymize_user_fields(data):\n",
    "    if isinstance(data, dict):\n",
    "        if 'login' in data: # is a user dict\n",
    "            login = data['login']\n",
    "            return hide(login)\n",
    "        else:\n",
    "            return {k: anonymize_user_fields(v) for k, v in data.items()}\n",
    "    if isinstance(data, list):\n",
    "        return [anonymize_user_fields(i) for i in data]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('./data') # Change if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulls = []\n",
    "for pull_file in tqdm(list(data_dir.glob('repos/*/*/pulls.json.bz2'))):\n",
    "    pull_file_path = Path(pull_file)\n",
    "    for full_pull in load_data(pull_file_path):\n",
    "        pull = {field: full_pull[field] for field in ('id', 'number', 'state', 'created_at', 'closed_at', 'merged_at', 'author_association', 'user')}\n",
    "        pull = anonymize_user_fields(pull)\n",
    "\n",
    "        timeline_path = pull_file_path.parent / f'timelines/{pull[\"number\"]}.json.bz2'\n",
    "        try:\n",
    "            time_line_items = [item for item in load_data(timeline_path) if item['event'] != 'committed'] # we exclude commit events since the user data is not mapped to the GitHub datascheme\n",
    "        except FileNotFoundError:\n",
    "            print(f'{timeline_path} seems to be missing')\n",
    "            time_line_items = []\n",
    "        time_line_items = remove_fields(time_line_items, ('performed_via_github_app', 'label', 'reactions', 'commit_id', 'labels', 'repository', 'assignee', 'assignees', 'milestone', 'diff_hunk', 'path'))\n",
    "        time_line_items = anonymize_user_fields(time_line_items)\n",
    "\n",
    "        pull['timeline'] = time_line_items\n",
    "        pulls += [pull]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = []\n",
    "for pull in tqdm(pulls):\n",
    "    pull_id = pull['id']\n",
    "    events += [(pull['user'], pull['created_at'], 'created', pull_id)]\n",
    "    for event in pull['timeline']:\n",
    "        event_type = event['event']\n",
    "        match event_type:\n",
    "            case 'reviewed':\n",
    "                events += [(event['user'], event['submitted_at'], event_type, pull_id)]\n",
    "            case 'commit-commented' | 'line-commented':\n",
    "                for comment in event['comments']:\n",
    "                    events += [(comment['user'], comment['updated_at'], event_type, pull_id)]\n",
    "            case 'created' | 'closed' | 'commented' | 'reopened':\n",
    "                events += [(event['actor'], event['created_at'], event_type, pull_id)]\n",
    "            case _:\n",
    "                pass\n",
    "events = [event for event in events if event[0] in humans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = pd.DataFrame(events, columns=['user_id', 'timestamp', 'action', 'pr_id']).dropna()\n",
    "activities.timestamp = pd.to_datetime(activities.timestamp).dt.tz_localize(None)\n",
    "activities['month'] = activities.timestamp.to_numpy().astype('datetime64[M]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(user_location) == dict:\n",
    "    activities['country'] = activities.user_id.replace(user_location)\n",
    "else:\n",
    "    activities = activities.merge(user_location, how='left', left_on=['user_id', 'month'], right_on=['user_id', 'month'], validate='m:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plese find more information on modelling code review as communication channels here: https://dl.acm.org/doi/abs/10.1145/3544902.3546254\n",
    "\n",
    "start = activities.groupby('pr_id').timestamp.min().rename('start')\n",
    "end = activities.groupby('pr_id').timestamp.max().rename('end')\n",
    "countries = activities.groupby('pr_id').country.nunique(dropna=True).rename('countries')\n",
    "unclear = activities.set_index('pr_id').country.isnull().groupby(level=0).sum().rename('unclear')\n",
    "countries_max = (countries + unclear).rename('countries_max')\n",
    "\n",
    "communication_channels = pd.concat([start, end, countries, countries_max], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change time frame as needed\n",
    "sample_freq = '1M'\n",
    "sample_timeframe_1 = (datetime(2017,1,1)<=communication_channels.end) & (communication_channels.end<=datetime(2023,1,1))\n",
    "\n",
    "all_communication_channels = communication_channels[sample_timeframe_1].resample(sample_freq, on='end').start.count()\n",
    "crossborder_communication_channels = communication_channels[sample_timeframe_1 & (communication_channels.countries>1)].resample(sample_freq, on='end').start.count()\n",
    "crossborder_max_communication_channels = communication_channels[sample_timeframe_1 & (communication_channels.countries_max>1)].resample(sample_freq, on='end').start.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_y = (crossborder_communication_channels/all_communication_channels).rename('lower_crossborder').loc['2018-12-01':'2023-01-01']\n",
    "upper_y = (crossborder_max_communication_channels/all_communication_channels).rename('upper_crossborder').loc['2018-12-01':'2023-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6), dpi=300)\n",
    "\n",
    "x = lower_y.index\n",
    "ax.plot(x, lower_y, c='black', label='Clear location')\n",
    "\n",
    "ax.fill_between(x, lower_y, upper_y, color='red', alpha=0.25, label='Unclear location')\n",
    "ax.set_ylabel('Cross-border code reviews');\n",
    "ax.set_xlabel('');\n",
    "\n",
    "\n",
    "years = mdates.YearLocator()\n",
    "months = mdates.MonthLocator()\n",
    "monthsFmt = mdates.DateFormatter('%b')\n",
    "yearsFmt = mdates.DateFormatter('%Y')\n",
    "\n",
    "ax.xaxis.set_minor_locator(months)\n",
    "\n",
    "ax.set_xbound((pd.Timestamp('2019-01-01'), pd.Timestamp('2023-01-01')))\n",
    "\n",
    "plt.grid(which='major')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
